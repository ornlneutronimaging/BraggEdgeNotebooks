{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the 'binnning_list_of_files.csv' files produced by step3 notebook, this notebook will produced the rebinned files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import custom_style; \n",
    "custom_style.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from ipywidgets.widgets import interact\n",
    "from ipywidgets import widgets\n",
    "\n",
    "from pprint import pprint\n",
    "import pyfits\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from plotly.offline import plot, init_notebook_mode, iplot\n",
    "init_notebook_mode()\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from IPython.html import widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_folder = '/Volumes/My Book Thunderbolt Duo/IPTS/BraggEdge/SNAP/SNAP_August_September_2015/'\n",
    "file_name = root_folder + 'binning_list_of_files.csv'\n",
    "df = pd.read_csv(file_name, index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_files_to_merge = []\n",
    "list_times = []\n",
    "list_temperature = []\n",
    "\n",
    "for _files in df.loc['list_of_files',:]:\n",
    "    list_files_to_merge.append(_files.split(';;'))\n",
    "    \n",
    "for _time in df.loc['binned_file_time',:]:\n",
    "    list_times.append(_time)\n",
    "    \n",
    "for _temp in df.loc['temperature',:]:\n",
    "    list_temperature.append(_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data_name = {}\n",
    "w = widgets.IntProgress()\n",
    "w.max = len(list_files_to_merge)\n",
    "display(w)\n",
    "\n",
    "for _index, _files in enumerate(list_files_to_merge):\n",
    "    \n",
    "    bin_data = []\n",
    "    \n",
    "    for _file in _files:\n",
    "\n",
    "        #retrieve prefix image number   ex: Image0001_0000.fits -> Image0001\n",
    "        _dirname = os.path.dirname(_file)\n",
    "        _basename = os.path.basename(_file)\n",
    "        _basename_splitted = _basename.split('_')\n",
    "    \n",
    "        #get full list of image with such a prefix (using glob)\n",
    "        _full_list = glob.glob(_dirname + '/' + _basename_splitted[0] + '_*.fits')\n",
    "                \n",
    "        #store list bin_data.append['file1','file2','file3']\n",
    "        bin_data.append(_full_list)\n",
    "        \n",
    "    #store in full_data dictionary\n",
    "    # full_data_name{'bin_number': bin_data}\n",
    "    bin_number  = \"%.4d\"%_index\n",
    "    full_data_name[_index] = bin_data\n",
    "    \n",
    "    w.value = _index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(full_data_name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "x = list_times\n",
    "y = list_temperature\n",
    "\n",
    "plt.step(x, y, where='mid')\n",
    "plt.xlabel(\"Time (span)\")\n",
    "plt.ylabel(\"Temperature(C)\")\n",
    "plt.title(\"Progress of Rebinned Files Created\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Median\n",
    "\n",
    "Not implemented yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithm = 'median'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean\n",
    "Not implemented yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithm = 'mean'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_folder = root_folder + 'rebinned_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algorithm = 'add'\n",
    "\n",
    "def add(data_arrays):\n",
    "    return np.sum(data_arrays)\n",
    "\n",
    "data_rebinned = []\n",
    "\n",
    "for _index, _files in enumerate(list_files_to_merge):\n",
    "    \n",
    "    data = read_fits(_files)\n",
    "    if len(data) == 1:\n",
    "        data_rebinned.append(data)\n",
    "    \n",
    "    _sum_data = data[0]\n",
    "    for _index_data in range(1, len(data)):\n",
    "        _sum_data += np.add(_sum_data, data[_index_data])\n",
    "    data_rebinned.append(_sum_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_fits(list_files):\n",
    "    '''takes a list of files, load them using pyfits and return a list of \n",
    "    arrays of data\n",
    "    '''\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    for _file in list_files:\n",
    "\n",
    "        hdu_list = pyfits.open(_file)  # fits\n",
    "        hdu = hdu_list[0]\n",
    "        _image = hdu.data\n",
    "        _image = np.asarray(_image)\n",
    "        data.append(_image)\n",
    "\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name_prefix = 'Image000'\n",
    "\n",
    "def make_output_file_name(_files_to_merge, suffix, algorithm='add'):\n",
    "    '''\n",
    "    takes the list of files to add and create the output file name \n",
    "    \n",
    "    Paramters:\n",
    "        * _files_to_merge: list of files to merge\n",
    "        * suffix: last 4 digits of file names\n",
    "        * algorithm: (optional) default value 'add'. Name of algorithm used to bin data\n",
    "            will be used in the new output file name\n",
    "            \n",
    "    Return:\n",
    "        * string file name of the output file\n",
    "        \n",
    "    Example:\n",
    "        _files_to_merge = []'/Users/me/Image0001_00000.fits','/Users/me/Image0002_00000.fits']\n",
    "        \n",
    "        will return  'Image00001_Image00002_0000_add.fits\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ext = '.fits'\n",
    "    list_output_file_name = []\n",
    "    \n",
    "    for _file in _files_to_merge:\n",
    "            _basename = os.path.basename(_file)\n",
    "            _basename_splitted = _basename.split('_')\n",
    "            list_output_file_name.append(_basename_splitted[0])\n",
    "\n",
    "    _output_file_name = '_'.join(list_output_file_name)\n",
    "    return _output_file_name + '_' + algorithm + ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for _index, data in enumerate(data_rebinned):\n",
    "    _files_to_merge = list_files_to_merge[_index]\n",
    "    _output_file_name = make_output_file_name(_files_to_merge, algorithm=algorithm)\n",
    "    _full_output_file_name = output_folder + _output_file_name\n",
    "\n",
    "    hdu = pyfits.PrimaryHDU(data)\n",
    "    hdulist = pyfits.HDUList([hdu])\n",
    "    hdulist.writeto(_full_output_file_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
